<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>NEURAVERS - Simple autocorrect system</title>
        <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico">
        <!-- Stylesheets -->
        <link rel="stylesheet" href="/css/main.css">
        <link rel="stylesheet" href="/css/header.css">
        <link rel="stylesheet" href="/css/footer.css">
        <link rel="stylesheet" href="/css/post.css">
        <link rel="stylesheet" href="/css/prism.css">
        <link
        rel="stylesheet"
            href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css"
            integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP"
            crossorigin="anonymous">
        <!-- JavaScript -->
        <script src="https://code.jquery.com/jquery-3.7.0.min.js"></script>
        <script src="/js/header.js" defer></script>
        <script src="/js/prism.js" defer></script>
        <script src="/js/post.js" defer></script>
        <script
            defer
            src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js"
            integrity="sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6"
            crossorigin="anonymous"></script>
        <script
            defer
            src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js"
            integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh"
            crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>
    </head>
    <body>
        <header>
            <div id="logo-container">
                <img src="/images/logo.png" alt="Neuravers logo">
            </div>
            <span id="blog-name">NEURAVERS</span>
            <div id="menu-container">
                <nav>
                    <ul>
                        <li><a href="/" style="color: #999999;">Home</a></li>
                        <li><a href="/blog/" style="color: #999999;">Blog</a></li>
                        <li><a href="/about/" style="color: #999999;">About</a></li>
                        <li><a class="contact-button" style="color: #999999;">Contact</a></li>
                    </ul>
                </nav>
                <div id="menu-button">
                    <span></span>
                    <span></span>
                    <span></span>
                    <span></span>
                </div>
                <div id="sidebar-menu">
                    <nav>
                        <ul>
                            <li><a href="/" style="color: #999999;">Home</a></li>
                            <li><a href="/blog/" style="color: #999999;">Blog</a></li>
                            <li><a href="/about/" style="color: #999999;">About</a></li>
                            <li><a class="contact-button" style="color: #999999;">Contact</a></li>
                        </ul>
                    </nav>
                    <div id="language-selector">
                        <img src="/images/language-english.png" alt="English language">
                        <span>English</span>
                        <img src="/images/arrow-down.png" alt="Arrow down">
                    </div>
                </div>
            </div>
            <div id="language-popup">
                There are no other languages available at the moment.
            </div>
        </header>
        <main>
            <section id="main-section" data-pagefind-body>
                <div>
                    <h5>NLP</h5>
                    <h5>6 min read</h5>
                </div>
                <h1>Simple autocorrect system</h1>
                <p>A short post explaining how a simple probabilistic autocorrect system works. I show how to build it and briefly mention more advanced systems used by big tech companies.</p>
                <img src="/images/abstract3.png" alt="Post main section image"/>
                <span></span>
            </section>
            <div>
                <article data-pagefind-body>
                    <section><h1>Introduction</h1>
<p><strong>Have you ever wondered how it is that our phone automatically corrects words when we make a mistake?</strong>
In this post, <strong>I'll show you how to build a simple autocorrect system!</strong>
It will be a <strong>basic probabilistic model</strong> that, despite its simplicity, <strong>performs quite well</strong>.
Keep in mind that companies like <strong>Google</strong> and <strong>Apple</strong> have their own autocorrection systems, which can be more advanced and use <strong>attention-based algorithms</strong> (<a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a>) to more accurately correct words depending on the <strong>context</strong>.</p>
</section><section><h1><strong>How the Algorithm Works</strong></h1>
<ol>
<li><strong>Find the misspelled word.</strong></li>
<li><strong>Find the words that are most similar to the input.</strong></li>
<li><strong>Select the most probable word based on a heuristic.</strong></li>
</ol>
<p><strong>How do we know if a word is spelled correctly?</strong>
Let’s choose the <strong>most intuitive approach</strong> – one we can quickly arrive at with a bit of reasoning.
We simply check whether the entered word <strong>exists in a dictionary</strong>, which by definition is a set of <strong>valid words in a given language</strong>.</p>
<p>In the next step, we need to <strong>somehow determine which words</strong> in the dictionary are the most likely alternatives to what the user intended to write.
To do this, we will use the <strong>Levenshtein distance</strong>, which calculates the <strong>number of operations required</strong> to transform one word into another.</p>
<p>Finally, we will <strong>sort the candidate words</strong> by the <strong>number of required operations</strong> (in ascending order), and among those with the fewest changes, we will <strong>select the word(s) that appear most frequently</strong> in a language corpus.</p>
</section><section><h1><strong>Preprocessing the Data</strong></h1>
<p>We will need a <strong>dictionary</strong> and a <strong>list of probabilities</strong> indicating how likely each word is to occur in a text.
To achieve this, we will <strong>input a large text file</strong> containing content written in <strong>Polish</strong>.</p>
<p>It’s important to ensure that the words in this file are <strong>correctly spelled</strong> — otherwise, our system might <strong>learn incorrect spellings</strong> and start "<strong>correcting</strong>" valid words into <strong>invalid ones</strong>.</p>
<p>Next, we will <strong>clean the text</strong> by removing all <strong>unwanted characters</strong> such as <strong>punctuation marks</strong> and <strong>capital letters</strong>.
(This may cause some issues with <strong>proper nouns</strong>, which are usually capitalized, but it allows us to <strong>reduce the dictionary size</strong> in a simple way).</p>
<p>Below is the <strong>Python code</strong> that performs this <strong>preprocessing</strong>:</p>
<pre><code class="language-python"># Load data from a text file
text = ""
with open('polish_text.txt', 'r', encoding='utf-8') as file:
    text = file.read()

# Remove all punctuation marks
import string
text = text.translate(str.maketrans('', '', string.punctuation + "—" + "…" + "“" + "”" + "‘" + "’" +"„"))

# Convert all letters to lowercase
text = text.lower()

# Split text into words
words = text.split()

# Create a dictionary of unique words
unique_words = set(words)

# Create a dictionary with the count of each word's occurrences
word_count = {}
for word in words:
    if word in word_count:
        word_count[word] += 1
    else:
        word_count[word] = 1

# Create a dictionary with probabilities of each word's occurrences
total_words = len(words)
word_probabilities = {}
for word, count in word_count.items(): # (word, count) pairs from word_count
    word_probabilities[word] = count / total_words

# Create a dictionary with words grouped by their length
words_by_length = {}
for word in unique_words:
    length = len(word)
    if length not in words_by_length:
        words_by_length[length] = []
    words_by_length[length].append(word)
</code></pre>
</section><section><h1>Implementation</h1>
<p><strong>Let’s implement the Levenshtein algorithm</strong>, which calculates the <strong>minimum number of operations</strong> required to transform one word into another.</p>
<p>This algorithm uses <strong>dynamic programming</strong> to break down the main problem —
<strong>"find the minimum number of operations to convert <code>s1</code> to <code>s2</code></strong> —
into smaller subproblems: specifically,
<strong>"find the minimum number of operations to convert <code>s1[:i]</code> to <code>s2[:j]</code>.</strong></p>
<p>In each iteration, we will use <strong>values that were previously computed</strong> and <strong>stored in a table</strong>.</p>
<p>In a future post, I’ll go into more detail about <strong>dynamic programming</strong>, but for now, it's important to understand that it's <strong>not a programming paradigm</strong> (like <strong>object-oriented</strong> or <strong>functional programming</strong>), but rather a <strong>method for solving problems efficiently</strong>.</p>
<pre><code class="language-python">def levenshtein_distance(s1, s2):
    # s1 = source, s2 = target
    n = len(s1) + 1  # add an empty character at the beginning of s1
    m = len(s2) + 1  # add an empty character at the beginning of s2
    matrix = np.zeros((n, m), dtype=int)

    # The two loops below are used so that we don't have to check bounds in the main loop.
    # The number of operations needed to convert s1[:i] to an empty string (i.e., deletions)
    for i in range(n):
        matrix[i][0] = i

    # The number of operations needed to convert an empty string to s2[:j] (i.e., insertions)
    for j in range(m):
        matrix[0][j] = j

    # Compute the Levenshtein distance
    for i in range(1, n):
        for j in range(1, m):
            if s1[i - 1] == s2[j - 1]:
                matrix[i][j] = matrix[i - 1][j - 1]  # Characters are the same, no operation needed
            else:
                matrix[i][j] = min(
                    matrix[i - 1][j] + 1,
                    matrix[i][j - 1] + 1,
                    matrix[i - 1][j - 1] + 1
                )

    return matrix[n - 1][m - 1]
</code></pre>
<p><strong>With this set of tools, we proceed to implement the autocorrect system according to our pseudocode.</strong></p>
<pre><code class="language-python">def autocorrect(word, edit_distance=3):
    # Preprocess the input word
    word = word.strip().lower()
    word = word.translate(str.maketrans('', '', string.punctuation + "—" + "…" + "“" + "”" + "‘" + "’" +"„")) # Remove punctuation and special characters

    # Check if there is a mistake in the word
    if word in unique_words:
        return word # Word is correct, do nothing
    
    # else: correct the word

    # Find words with the same length or similar length
    suggested_words_length = [len(word)] # Can be adjusted to include more lengths, e.g., [len(word) - 1, len(word), len(word) + 1]
    
    # Find similar words
    similar_words = []
    for length in suggested_words_length:
        # Check if the candidate word is similar enough
        if levenshtein_distance(word, candidate) &lt;= edit_distance and candidate.startswith(word[0]):
            similar_words.append(candidate)

    # If no similar words found, return the original word (it might be correct but not in the dictionary)
    if not similar_words:
        return word
    
    # Otherwise, select the most probable correction among the closest words
    
    # Sort by Levenshtein distance (Smallest first)
    similar_words.sort(key=lambda x: levenshtein_distance(word, x), reverse=False)

    # Get all words with minimum Levenshtein distance
    min_distance = levenshtein_distance(word, similar_words[0])
    temp = [w for w in similar_words if levenshtein_distance(word, w) == min_distance]

    # Sort by probability (Highest first)
    temp.sort(key=lambda x: word_probabilities.get(x, 0), reverse=True)

    # Return the most probable word
    return temp[0]
</code></pre>
</section><section><h1>Testing</h1>
<p><strong>Let's test how well our autocorrect system performs</strong> on the following set of words, which appear in the input data:</p>
<blockquote>
<p><strong>Mały Książę miał zupełnie Dorośli są naprawdę róża zagrożona rychłym wyginięciem radziłby dać wyglądało mógłbym wąż Ziemię cię że jesteście skały się</strong></p>
</blockquote>
<p><strong>Input data:</strong></p>
<blockquote>
<p>maly ksiaze mial zupelnie dorosli sa naprawde razy zagrozona rychlym wygninieciem radzilby dac wygladalo moglbym was ziemie cie ze jestescie skaly sie</p>
</blockquote>
<p><strong>Output data:</strong></p>
<blockquote>
<p>mały książę miał zupełnie dorośli są naprawdę razy zagrożona rychłym wyginięciem radziłby dać wyglądało mógłbym was ziemię cię ze jesteście skały się</p>
</blockquote>
<p>This is a <strong>satisfying initial result</strong>, but I encourage you to <strong>explore more broadly</strong> how the system performs in different cases!</p>
<br>
<p>You can find the full code here: <a href="https://github.com/neuravers/simple-autocorrect">Simple autocorrect</a>.</p>
</section>
                </article>
                <aside>
                    <ul><li><a href="#section-heading-1">Introduction</a></li><li><a href="#section-heading-2">How the Algorithm Works</a></li><li><a href="#section-heading-3">Preprocessing the Data</a></li><li><a href="#section-heading-4">Implementation</a></li><li><a href="#section-heading-5">Testing</a></li></ul>
                    <button id="toc-toggle" aria-expanded="false"><img src="/images/arrow-down-off.png" alt="Table of Contents">
                    </button>
                </aside>
            </div>
        </main>
        <footer>
            <div>
                <div id="footer-logo">
                    <img src="/images/logo.png" alt="Neuravers logo">
                    <h4>NEURAVERS</h4>
                </div>
                <p>&copy; 2025 Neuravers. All rights reserved.</p>
            </div>
        </footer>
    </body>
</html>